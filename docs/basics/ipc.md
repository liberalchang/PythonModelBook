---
layout: doc
title: Python è¿›ç¨‹é—´é€šä¿¡ï¼ˆIPCï¼‰
permalink: /docs/basics/ipc/
category: basics
tags: [è¿›ç¨‹é—´é€šä¿¡, IPC, Pipe, Queue, multiprocessing]
description: æŒæ¡ Python ä¸­è¿›ç¨‹é—´é€šä¿¡çš„å„ç§æœºåˆ¶ï¼ŒåŒ…æ‹¬ç®¡é“ã€é˜Ÿåˆ—å’ŒåŒæ­¥åŸè¯­
author: Python ç¼–ç¨‹æŒ‡å—
date: 2024-01-15
updated: 2024-01-15
version: 1.0
difficulty: "ä¸­çº§"
---

# Python è¿›ç¨‹é—´é€šä¿¡ï¼ˆIPCï¼‰

## ğŸ“ æ¦‚è¿°

ç”±äºè¿›ç¨‹é—´ä¸å…±äº«å†…å­˜ç©ºé—´ï¼Œéœ€è¦ç‰¹æ®Šçš„é€šä¿¡æœºåˆ¶è¿›è¡Œæ•°æ®äº¤æ¢ã€‚Python `multiprocessing` æ¨¡å—æä¾›äº†å¤šç§è¿›ç¨‹é—´é€šä¿¡ï¼ˆIPCï¼‰æ–¹å¼ï¼ŒåŒ…æ‹¬ç®¡é“ï¼ˆPipeï¼‰ã€é˜Ÿåˆ—ï¼ˆQueueï¼‰å’ŒåŒæ­¥åŸè¯­ï¼ˆLockã€RLockï¼‰ç­‰ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- æŒæ¡ç®¡é“ï¼ˆPipeï¼‰çš„ä½¿ç”¨å’Œæ³¨æ„äº‹é¡¹
- ç†è§£å„ç§é˜Ÿåˆ—ï¼ˆQueueã€SimpleQueueã€JoinableQueueï¼‰çš„ç‰¹ç‚¹
- å­¦ä¼šä½¿ç”¨å¤šè¿›ç¨‹åŒæ­¥åŸè¯­
- äº†è§£å¹¶å‘å¤„ç†ä¸­çš„å®‰å…¨é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- æŒæ¡è¿›ç¨‹é—´æ•°æ®ä¼ é€’çš„æœ€ä½³å®è·µ

## ğŸ“‹ å‰ç½®çŸ¥è¯†

- å¤šè¿›ç¨‹ç¼–ç¨‹åŸºç¡€
- Python å¼‚å¸¸å¤„ç†
- å¹¶å‘ç¼–ç¨‹æ¦‚å¿µ
- åºåˆ—åŒ–ä¸ååºåˆ—åŒ–ï¼ˆpickleï¼‰

## ğŸ” è¯¦ç»†å†…å®¹

### 1. ç®¡é“ï¼ˆPipeï¼‰

ç®¡é“æä¾›äº†ä¸¤ä¸ªè¿›ç¨‹é—´çš„åŒå‘é€šä¿¡é€šé“ã€‚

#### åŸºæœ¬ä½¿ç”¨

```python
from multiprocessing import Process, Pipe

def sender(conn):
    """å‘é€æ•°æ®çš„è¿›ç¨‹"""
    conn.send(['æ•°æ®', 42, None])
    conn.send('ä½ å¥½ï¼Œè¿›ç¨‹é€šä¿¡ï¼')
    conn.close()

def receiver(conn):
    """æ¥æ”¶æ•°æ®çš„è¿›ç¨‹"""
    print("æ¥æ”¶åˆ°:", conn.recv())  # ['æ•°æ®', 42, None]
    print("æ¥æ”¶åˆ°:", conn.recv())  # 'ä½ å¥½ï¼Œè¿›ç¨‹é€šä¿¡ï¼'
    conn.close()

if __name__ == '__main__':
    # åˆ›å»ºç®¡é“
    parent_conn, child_conn = Pipe()
    
    # åˆ›å»ºè¿›ç¨‹
    p1 = Process(target=sender, args=(child_conn,))
    p2 = Process(target=receiver, args=(parent_conn,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
```

#### Connection å¯¹è±¡çš„å±æ€§å’Œæ–¹æ³•

```python
from multiprocessing import Pipe
import os

def explore_connection():
    """æ¢ç´¢ Connection å¯¹è±¡çš„å±æ€§å’Œæ–¹æ³•"""
    parent_conn, child_conn = Pipe()
    
    print("Connection å¯¹è±¡å±æ€§:")
    print(f"å¯è¯»: {parent_conn.readable}")
    print(f"å¯å†™: {parent_conn.writable}")
    print(f"æ–‡ä»¶æè¿°ç¬¦: {parent_conn.fileno()}")
    
    # ä¸»è¦æ–¹æ³•
    print("\nConnection å¯¹è±¡æ–¹æ³•:")
    print("send(obj) - å‘é€å¯¹è±¡")
    print("recv() - æ¥æ”¶å¯¹è±¡")
    print("send_bytes(buffer) - å‘é€å­—èŠ‚")
    print("recv_bytes() - æ¥æ”¶å­—èŠ‚")
    print("poll([timeout]) - æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®å¯è¯»")
    print("close() - å…³é—­è¿æ¥")

if __name__ == '__main__':
    explore_connection()
```

#### ç®¡é“çš„å¹¶å‘é—®é¢˜

```python
from multiprocessing import Process, Pipe
import time
import random

def concurrent_sender(conn, sender_id, count=5):
    """å¹¶å‘å‘é€æ•°æ®"""
    for i in range(count):
        message = f"å‘é€è€…{sender_id}: æ¶ˆæ¯{i}"
        conn.send(message)
        print(f"[å‘é€] {message}")
        time.sleep(random.uniform(0.1, 0.5))
    conn.close()

def concurrent_receiver(conn, total_messages):
    """å¹¶å‘æ¥æ”¶æ•°æ®"""
    received = 0
    while received < total_messages:
        try:
            if conn.poll(1):  # è¶…æ—¶1ç§’
                message = conn.recv()
                print(f"[æ¥æ”¶] {message}")
                received += 1
            else:
                print("æ¥æ”¶è¶…æ—¶...")
                break
        except EOFError:
            print("ç®¡é“å·²å…³é—­")
            break
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    
    # åˆ›å»ºå¤šä¸ªå‘é€è¿›ç¨‹
    sender_count = 3
    message_per_sender = 3
    total_messages = sender_count * message_per_sender
    
    senders = []
    for i in range(sender_count):
        p = Process(target=concurrent_sender, 
                   args=(child_conn, i, message_per_sender))
        senders.append(p)
        p.start()
    
    # åˆ›å»ºæ¥æ”¶è¿›ç¨‹
    receiver = Process(target=concurrent_receiver, 
                      args=(parent_conn, total_messages))
    receiver.start()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in senders:
        p.join()
    
    receiver.join()
    print("ç®¡é“é€šä¿¡æ¼”ç¤ºå®Œæˆ")
```

### 2. é˜Ÿåˆ—ï¼ˆQueueï¼‰

é˜Ÿåˆ—æä¾›äº†æ›´å®‰å…¨çš„å¤šè¿›ç¨‹é€šä¿¡æ–¹å¼ï¼Œå†…ç½®äº†åŒæ­¥æœºåˆ¶ã€‚

#### Queue - æ ‡å‡†é˜Ÿåˆ—

```python
from multiprocessing import Process, Queue
import time
import random

def producer(q, producer_id):
    """ç”Ÿäº§è€…è¿›ç¨‹"""
    for i in range(5):
        item = f"ç”Ÿäº§è€…{producer_id}çš„äº§å“{i}"
        q.put(item)
        print(f"[ç”Ÿäº§] {item}")
        time.sleep(random.uniform(0.1, 0.3))
    
    # å‘é€ç»“æŸä¿¡å·
    q.put(None)

def consumer(q, consumer_id):
    """æ¶ˆè´¹è€…è¿›ç¨‹"""
    while True:
        item = q.get()
        if item is None:
            # æ”¶åˆ°ç»“æŸä¿¡å·ï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—ä¾›å…¶ä»–æ¶ˆè´¹è€…
            q.put(None)
            break
        
        print(f"[æ¶ˆè´¹è€…{consumer_id}] å¤„ç†: {item}")
        time.sleep(random.uniform(0.2, 0.4))

if __name__ == '__main__':
    # åˆ›å»ºé˜Ÿåˆ—
    q = Queue(maxsize=10)  # é™åˆ¶é˜Ÿåˆ—å¤§å°
    
    # åˆ›å»ºç”Ÿäº§è€…è¿›ç¨‹
    producers = []
    for i in range(2):
        p = Process(target=producer, args=(q, i))
        producers.append(p)
        p.start()
    
    # åˆ›å»ºæ¶ˆè´¹è€…è¿›ç¨‹
    consumers = []
    for i in range(3):
        p = Process(target=consumer, args=(q, i))
        consumers.append(p)
        p.start()
    
    # ç­‰å¾…ç”Ÿäº§è€…å®Œæˆ
    for p in producers:
        p.join()
    
    # å‘é€ç»“æŸä¿¡å·
    q.put(None)
    
    # ç­‰å¾…æ¶ˆè´¹è€…å®Œæˆ
    for p in consumers:
        p.join()
    
    print("é˜Ÿåˆ—é€šä¿¡æ¼”ç¤ºå®Œæˆ")
```

#### SimpleQueue - ç®€åŒ–é˜Ÿåˆ—

```python
from multiprocessing import Process, SimpleQueue
import time

def simple_producer(q):
    """ç®€å•ç”Ÿäº§è€…"""
    for i in range(5):
        q.put(f"ç®€å•æ¶ˆæ¯{i}")
        print(f"å‘é€: ç®€å•æ¶ˆæ¯{i}")
        time.sleep(0.5)

def simple_consumer(q):
    """ç®€å•æ¶ˆè´¹è€…"""
    for _ in range(5):
        message = q.get()
        print(f"æ¥æ”¶: {message}")

if __name__ == '__main__':
    # SimpleQueue ä¸æ”¯æŒ maxsize å‚æ•°
    sq = SimpleQueue()
    
    p1 = Process(target=simple_producer, args=(sq,))
    p2 = Process(target=simple_consumer, args=(sq,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
    
    print("SimpleQueue æ¼”ç¤ºå®Œæˆ")
```

#### JoinableQueue - å¯è¿æ¥é˜Ÿåˆ—

```python
from multiprocessing import Process, JoinableQueue
import time
import random

def task_producer(q):
    """ä»»åŠ¡ç”Ÿäº§è€…"""
    tasks = ['ä»»åŠ¡A', 'ä»»åŠ¡B', 'ä»»åŠ¡C', 'ä»»åŠ¡D', 'ä»»åŠ¡E']
    
    for task in tasks:
        q.put(task)
        print(f"æ·»åŠ ä»»åŠ¡: {task}")
        time.sleep(0.2)

def task_worker(q, worker_id):
    """ä»»åŠ¡å·¥ä½œè€…"""
    while True:
        task = q.get()
        if task is None:
            q.task_done()  # æ ‡è®° None ä»»åŠ¡å®Œæˆ
            break
        
        print(f"[å·¥ä½œè€…{worker_id}] å¼€å§‹å¤„ç†: {task}")
        time.sleep(random.uniform(1, 2))  # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†æ—¶é—´
        print(f"[å·¥ä½œè€…{worker_id}] å®Œæˆ: {task}")
        
        q.task_done()  # æ ‡è®°ä»»åŠ¡å®Œæˆ

if __name__ == '__main__':
    jq = JoinableQueue()
    
    # å¯åŠ¨ç”Ÿäº§è€…
    producer = Process(target=task_producer, args=(jq,))
    producer.start()
    
    # å¯åŠ¨å·¥ä½œè€…
    workers = []
    for i in range(3):
        w = Process(target=task_worker, args=(jq, i))
        w.start()
        workers.append(w)
    
    # ç­‰å¾…ç”Ÿäº§è€…å®Œæˆ
    producer.join()
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    jq.join()
    print("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ!")
    
    # å‘é€åœæ­¢ä¿¡å·ç»™å·¥ä½œè€…
    for _ in workers:
        jq.put(None)
    
    # ç­‰å¾…å·¥ä½œè€…é€€å‡º
    for w in workers:
        w.join()
    
    print("JoinableQueue æ¼”ç¤ºå®Œæˆ")
```

### 3. å¤šè¿›ç¨‹åŒæ­¥åŸè¯­

#### Lock - äº’æ–¥é”

```python
from multiprocessing import Process, Lock
import time

# å…±äº«èµ„æºï¼ˆæ–‡ä»¶ï¼‰
SHARED_FILE = 'shared_counter.txt'

def write_to_file(lock, process_id, count):
    """ä½¿ç”¨é”ä¿æŠ¤æ–‡ä»¶å†™å…¥"""
    for i in range(count):
        with lock:  # è·å–é”
            try:
                # è¯»å–å½“å‰å€¼
                try:
                    with open(SHARED_FILE, 'r') as f:
                        current = int(f.read().strip() or '0')
                except FileNotFoundError:
                    current = 0
                
                # å¢åŠ å€¼
                current += 1
                
                # å†™å›æ–‡ä»¶
                with open(SHARED_FILE, 'w') as f:
                    f.write(str(current))
                
                print(f"è¿›ç¨‹{process_id}: å†™å…¥å€¼ {current}")
                
            except Exception as e:
                print(f"è¿›ç¨‹{process_id} å‡ºé”™: {e}")
        
        time.sleep(0.1)  # æ¨¡æ‹Ÿå…¶ä»–å·¥ä½œ

if __name__ == '__main__':
    # æ¸…ç†æ–‡ä»¶
    try:
        with open(SHARED_FILE, 'w') as f:
            f.write('0')
    except:
        pass
    
    lock = Lock()
    
    # åˆ›å»ºå¤šä¸ªè¿›ç¨‹
    processes = []
    for i in range(3):
        p = Process(target=write_to_file, args=(lock, i, 5))
        processes.append(p)
        p.start()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    # è¯»å–æœ€ç»ˆç»“æœ
    try:
        with open(SHARED_FILE, 'r') as f:
            final_value = f.read().strip()
        print(f"æœ€ç»ˆè®¡æ•°å™¨å€¼: {final_value}")
    except FileNotFoundError:
        print("æ–‡ä»¶æœªæ‰¾åˆ°")
```

#### RLock - å¯é‡å…¥é”

```python
from multiprocessing import Process, RLock
import time

def recursive_function(rlock, process_id, depth, max_depth=3):
    """é€’å½’å‡½æ•°æ¼”ç¤º RLock çš„å¯é‡å…¥æ€§"""
    if depth > max_depth:
        return
    
    with rlock:
        print(f"è¿›ç¨‹{process_id}: è¿›å…¥å±‚çº§ {depth}")
        time.sleep(0.1)
        
        # é€’å½’è°ƒç”¨ - RLock å…è®¸åŒä¸€è¿›ç¨‹å¤šæ¬¡è·å–é”
        recursive_function(rlock, process_id, depth + 1, max_depth)
        
        print(f"è¿›ç¨‹{process_id}: é€€å‡ºå±‚çº§ {depth}")

if __name__ == '__main__':
    rlock = RLock()
    
    processes = []
    for i in range(2):
        p = Process(target=recursive_function, args=(rlock, i, 1))
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
    
    print("RLock æ¼”ç¤ºå®Œæˆ")
```

## ğŸ’¡ å®é™…åº”ç”¨

### å¤šè¿›ç¨‹æ—¥å¿—æ”¶é›†ç³»ç»Ÿ

```python
from multiprocessing import Process, Queue, current_process
import time
import random
import logging
from datetime import datetime

def log_collector(log_queue):
    """æ—¥å¿—æ”¶é›†è¿›ç¨‹"""
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        filename='multiprocess.log'
    )
    
    logger = logging.getLogger('LogCollector')
    
    while True:
        try:
            # è·å–æ—¥å¿—æ¶ˆæ¯ï¼ˆè¶…æ—¶3ç§’ï¼‰
            log_record = log_queue.get(timeout=3)
            
            if log_record is None:  # ç»“æŸä¿¡å·
                logger.info("æ—¥å¿—æ”¶é›†å™¨æ­£åœ¨å…³é—­...")
                break
            
            # å†™å…¥æ—¥å¿—
            logger.info(f"[{log_record['process']}] {log_record['message']}")
            
        except Exception as e:
            logger.error(f"æ—¥å¿—æ”¶é›†å‡ºé”™: {e}")

def worker_process(process_id, log_queue, work_duration=10):
    """å·¥ä½œè¿›ç¨‹ - äº§ç”Ÿæ—¥å¿—"""
    start_time = time.time()
    
    while time.time() - start_time < work_duration:
        # æ¨¡æ‹Ÿå·¥ä½œå¹¶äº§ç”Ÿæ—¥å¿—
        work_type = random.choice(['å¤„ç†æ•°æ®', 'ç½‘ç»œè¯·æ±‚', 'æ–‡ä»¶æ“ä½œ', 'è®¡ç®—ä»»åŠ¡'])
        
        log_message = {
            'process': f'Worker-{process_id}',
            'message': f'æ­£åœ¨æ‰§è¡Œ: {work_type}',
            'timestamp': datetime.now().isoformat()
        }
        
        log_queue.put(log_message)
        
        # éšæœºå·¥ä½œæ—¶é—´
        time.sleep(random.uniform(0.5, 1.5))
    
    # å‘é€å®Œæˆæ¶ˆæ¯
    final_message = {
        'process': f'Worker-{process_id}',
        'message': 'å·¥ä½œå®Œæˆ',
        'timestamp': datetime.now().isoformat()
    }
    log_queue.put(final_message)

if __name__ == '__main__':
    # åˆ›å»ºæ—¥å¿—é˜Ÿåˆ—
    log_queue = Queue()
    
    # å¯åŠ¨æ—¥å¿—æ”¶é›†è¿›ç¨‹
    log_collector_process = Process(target=log_collector, args=(log_queue,))
    log_collector_process.start()
    
    # å¯åŠ¨å·¥ä½œè¿›ç¨‹
    workers = []
    for i in range(4):
        w = Process(target=worker_process, args=(i, log_queue, 5))
        workers.append(w)
        w.start()
    
    # ç­‰å¾…æ‰€æœ‰å·¥ä½œè¿›ç¨‹å®Œæˆ
    for w in workers:
        w.join()
    
    # å‘é€ç»“æŸä¿¡å·ç»™æ—¥å¿—æ”¶é›†å™¨
    log_queue.put(None)
    
    # ç­‰å¾…æ—¥å¿—æ”¶é›†å™¨å®Œæˆ
    log_collector_process.join()
    
    print("å¤šè¿›ç¨‹æ—¥å¿—æ”¶é›†æ¼”ç¤ºå®Œæˆ")
    print("æŸ¥çœ‹ multiprocess.log æ–‡ä»¶è·å–è¯¦ç»†æ—¥å¿—")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ç®¡é“å¹¶å‘é—®é¢˜**ï¼š
   - å¤šä¸ªè¿›ç¨‹åŒæ—¶å†™å…¥ä¸€ä¸ªç®¡é“å¯èƒ½å¯¼è‡´æ•°æ®æ··ä¹±
   - ä½¿ç”¨é˜Ÿåˆ—æ›¿ä»£ç®¡é“è¿›è¡Œå¤šå¯¹å¤šé€šä¿¡

2. **é˜Ÿåˆ—çš„é€‰æ‹©**ï¼š
   - `Queue`ï¼šåŠŸèƒ½å®Œæ•´ï¼Œæ”¯æŒå¤§å°é™åˆ¶
   - `SimpleQueue`ï¼šè½»é‡çº§ï¼Œæ— å¤§å°é™åˆ¶
   - `JoinableQueue`ï¼šæ”¯æŒä»»åŠ¡è·Ÿè¸ª

3. **é”çš„ä½¿ç”¨**ï¼š
   - è¿›ç¨‹é”å¼€é”€æ¯”çº¿ç¨‹é”å¤§
   - é¿å…æ­»é”ï¼šç»Ÿä¸€è·å–é”çš„é¡ºåº
   - ä½¿ç”¨ `with` è¯­å¥ç¡®ä¿é”çš„é‡Šæ”¾

4. **åºåˆ—åŒ–é™åˆ¶**ï¼š
   - é€šè¿‡ IPC ä¼ é€’çš„å¯¹è±¡å¿…é¡»å¯ pickle åºåˆ—åŒ–
   - æŸäº›å¯¹è±¡ï¼ˆå¦‚æ–‡ä»¶å¥æŸ„ã€é”ï¼‰æ— æ³•è·¨è¿›ç¨‹ä¼ é€’

## ğŸ”— ç›¸å…³å†…å®¹

- [å¤šè¿›ç¨‹ä¸è¿›ç¨‹æ± ](../multiprocessing/)
- [å­è¿›ç¨‹ä¸å¹¶è¡Œ](../subprocess/)
- [å¹¶è¡Œç¼–ç¨‹æ¦‚å¿µåŸºç¡€](../concurrency-concepts/)
- [å¤šçº¿ç¨‹ç¼–ç¨‹](../multithreading/)

## ğŸ“š æ‰©å±•é˜…è¯»

- [Python å®˜æ–¹æ–‡æ¡£ - multiprocessing](https://docs.python.org/3/library/multiprocessing.html)
- [Python å®˜æ–¹æ–‡æ¡£ - multiprocessing.Pipe](https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues)
- [Python å®˜æ–¹æ–‡æ¡£ - multiprocessing.Queue](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue)

## ğŸ·ï¸ æ ‡ç­¾

`è¿›ç¨‹é—´é€šä¿¡` `IPC` `Pipe` `Queue` `multiprocessing` `åŒæ­¥åŸè¯­`

---

**æœ€åæ›´æ–°**: 2024-01-15  
**ä½œè€…**: Python ç¼–ç¨‹æŒ‡å—  
**ç‰ˆæœ¬**: 1.0