# ord() - Unicodeç ç‚¹è·å–å‡½æ•°

## æ¦‚è¿°

`ord()` æ˜¯ Python çš„å†…ç½®å‡½æ•°ï¼Œç”¨äºè¿”å›å•ä¸ªå­—ç¬¦çš„ Unicode ç ç‚¹ï¼ˆæ•´æ•°å€¼ï¼‰ã€‚å®ƒæ˜¯ `chr()` å‡½æ•°çš„é€†æ“ä½œï¼Œå°†å­—ç¬¦è½¬æ¢ä¸ºå¯¹åº”çš„æ•´æ•°è¡¨ç¤ºã€‚

## å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬æ–‡æ¡£ï¼Œä½ å°†å­¦ä¼šï¼š
- ç†è§£ `ord()` å‡½æ•°çš„åŸºæœ¬æ¦‚å¿µå’Œç”¨é€”
- æŒæ¡ `ord()` å‡½æ•°çš„è¯­æ³•å’Œå‚æ•°
- å­¦ä¼šåœ¨å„ç§åœºæ™¯ä¸­ä½¿ç”¨ `ord()` å‡½æ•°
- äº†è§£ Unicode ç¼–ç å’Œå­—ç¬¦å¤„ç†
- æŒæ¡ç›¸å…³çš„æœ€ä½³å®è·µå’Œå¸¸è§é™·é˜±

## å‰ç½®çŸ¥è¯†

- Python åŸºç¡€è¯­æ³•
- å­—ç¬¦ä¸²å’Œå­—ç¬¦çš„åŸºæœ¬æ¦‚å¿µ
- Unicode ç¼–ç çš„åŸºæœ¬ç†è§£
- æ•°å€¼ç±»å‹çš„åŸºæœ¬æ“ä½œ

## è¯¦ç»†å†…å®¹

### åŸºæœ¬æ¦‚å¿µ

`ord()` å‡½æ•°æ¥å—ä¸€ä¸ªé•¿åº¦ä¸º 1 çš„å­—ç¬¦ä¸²ï¼ˆå³å•ä¸ªå­—ç¬¦ï¼‰ï¼Œè¿”å›è¯¥å­—ç¬¦å¯¹åº”çš„ Unicode ç ç‚¹ã€‚Unicode æ˜¯ä¸€ä¸ªå›½é™…æ ‡å‡†ï¼Œä¸ºä¸–ç•Œä¸Šå‡ ä¹æ‰€æœ‰çš„å­—ç¬¦åˆ†é…äº†å”¯ä¸€çš„æ•°å­—æ ‡è¯†ç¬¦ã€‚

### è¯­æ³•

```python
ord(c)
```

### å‚æ•°

- **c**: é•¿åº¦ä¸º 1 çš„å­—ç¬¦ä¸²ï¼ˆå•ä¸ªå­—ç¬¦ï¼‰ã€‚å¿…é¡»æ˜¯ Unicode å­—ç¬¦ã€‚

### è¿”å›å€¼

è¿”å›ä¸€ä¸ªæ•´æ•°ï¼Œè¡¨ç¤ºå­—ç¬¦ c çš„ Unicode ç ç‚¹ã€‚

### ä»£ç ç¤ºä¾‹

#### åŸºæœ¬ç”¨æ³•

```python
# ASCII å­—ç¬¦çš„ç ç‚¹
print(ord('A'))    # è¾“å‡º: 65
print(ord('a'))    # è¾“å‡º: 97
print(ord('0'))    # è¾“å‡º: 48
print(ord(' '))    # è¾“å‡º: 32 (ç©ºæ ¼)
print(ord('\n'))   # è¾“å‡º: 10 (æ¢è¡Œç¬¦)

# ç‰¹æ®Šå­—ç¬¦çš„ç ç‚¹
print(ord('!'))    # è¾“å‡º: 33
print(ord('@'))    # è¾“å‡º: 64
print(ord('#'))    # è¾“å‡º: 35

# ä¸­æ–‡å­—ç¬¦çš„ç ç‚¹
print(ord('ä¸­'))   # è¾“å‡º: 20013
print(ord('æ–‡'))   # è¾“å‡º: 25991
print(ord('ä½ '))   # è¾“å‡º: 20320
print(ord('å¥½'))   # è¾“å‡º: 22909

# å…¶ä»–è¯­è¨€å­—ç¬¦
print(ord('Î±'))    # è¾“å‡º: 945 (å¸Œè…Šå­—æ¯ alpha)
print(ord('Î²'))    # è¾“å‡º: 946 (å¸Œè…Šå­—æ¯ beta)
print(ord('Ï€'))    # è¾“å‡º: 960 (å¸Œè…Šå­—æ¯ pi)
```

#### å­—ç¬¦èŒƒå›´åˆ†æ

```python
# ASCII å­—ç¬¦èŒƒå›´åˆ†æ
def analyze_ascii_range():
    """åˆ†æ ASCII å­—ç¬¦èŒƒå›´"""
    ranges = {
        'æ§åˆ¶å­—ç¬¦': (0, 31),
        'å¯æ‰“å°å­—ç¬¦': (32, 126),
        'æ•°å­—': (48, 57),
        'å¤§å†™å­—æ¯': (65, 90),
        'å°å†™å­—æ¯': (97, 122)
    }
    
    print("ASCII å­—ç¬¦èŒƒå›´åˆ†æ:")
    for name, (start, end) in ranges.items():
        print(f"\n{name} ({start}-{end}):")
        
        # æ˜¾ç¤ºèŒƒå›´å†…çš„ä¸€äº›å­—ç¬¦
        sample_chars = []
        for code in range(start, min(end + 1, start + 10)):
            try:
                char = chr(code)
                if char.isprintable() or char in '\t\n\r':
                    sample_chars.append(f"'{char}'({code})")
                else:
                    sample_chars.append(f"æ§åˆ¶å­—ç¬¦({code})")
            except ValueError:
                sample_chars.append(f"æ— æ•ˆ({code})")
        
        print(f"  ç¤ºä¾‹: {', '.join(sample_chars)}")
        if end - start > 10:
            print(f"  ... è¿˜æœ‰ {end - start - 9} ä¸ªå­—ç¬¦")

# è°ƒç”¨åˆ†æå‡½æ•°
analyze_ascii_range()
```

#### Unicode å­—ç¬¦å·¥å…·ç±»

```python
import unicodedata

class UnicodeAnalyzer:
    """Unicode å­—ç¬¦åˆ†æå™¨"""
    
    @staticmethod
    def char_info(char):
        """è·å–å­—ç¬¦çš„è¯¦ç»†ä¿¡æ¯"""
        if len(char) != 1:
            raise ValueError("è¾“å…¥å¿…é¡»æ˜¯å•ä¸ªå­—ç¬¦")
        
        code_point = ord(char)
        
        info = {
            'character': char,
            'code_point': code_point,
            'hex_code': hex(code_point),
            'binary_code': bin(code_point),
            'unicode_name': unicodedata.name(char, 'æœªçŸ¥'),
            'category': unicodedata.category(char),
            'is_ascii': code_point < 128,
            'is_printable': char.isprintable(),
            'is_digit': char.isdigit(),
            'is_alpha': char.isalpha(),
            'is_alnum': char.isalnum(),
            'is_space': char.isspace(),
            'utf8_bytes': char.encode('utf-8'),
            'utf16_bytes': char.encode('utf-16le')
        }
        
        return info
    
    @staticmethod
    def compare_characters(chars):
        """æ¯”è¾ƒå¤šä¸ªå­—ç¬¦"""
        print(f"{'å­—ç¬¦':<5} {'ç ç‚¹':<8} {'åå…­è¿›åˆ¶':<10} {'ç±»åˆ«':<5} {'åç§°':<30}")
        print("-" * 70)
        
        for char in chars:
            try:
                info = UnicodeAnalyzer.char_info(char)
                print(f"{char:<5} {info['code_point']:<8} {info['hex_code']:<10} "
                      f"{info['category']:<5} {info['unicode_name'][:28]:<30}")
            except Exception as e:
                print(f"{char:<5} é”™è¯¯: {e}")
    
    @staticmethod
    def find_chars_in_range(start_code, end_code, max_results=20):
        """æŸ¥æ‰¾æŒ‡å®šç ç‚¹èŒƒå›´å†…çš„å­—ç¬¦"""
        found_chars = []
        
        for code in range(start_code, min(end_code + 1, start_code + max_results)):
            try:
                char = chr(code)
                if char.isprintable():
                    found_chars.append({
                        'char': char,
                        'code': code,
                        'hex': hex(code),
                        'name': unicodedata.name(char, 'æœªçŸ¥')
                    })
            except ValueError:
                continue
        
        return found_chars
    
    @staticmethod
    def analyze_string(text):
        """åˆ†æå­—ç¬¦ä¸²ä¸­æ‰€æœ‰å­—ç¬¦"""
        analysis = {
            'total_chars': len(text),
            'unique_chars': len(set(text)),
            'code_point_range': None,
            'categories': {},
            'encoding_sizes': {
                'utf8': len(text.encode('utf-8')),
                'utf16': len(text.encode('utf-16le')),
                'utf32': len(text.encode('utf-32le'))
            },
            'char_details': []
        }
        
        code_points = [ord(char) for char in text]
        if code_points:
            analysis['code_point_range'] = (min(code_points), max(code_points))
        
        # ç»Ÿè®¡å­—ç¬¦ç±»åˆ«
        for char in text:
            category = unicodedata.category(char)
            if category not in analysis['categories']:
                analysis['categories'][category] = 0
            analysis['categories'][category] += 1
        
        # è¯¦ç»†å­—ç¬¦ä¿¡æ¯ï¼ˆé™åˆ¶æ•°é‡é¿å…è¾“å‡ºè¿‡é•¿ï¼‰
        unique_chars = list(set(text))[:10]
        for char in unique_chars:
            try:
                char_info = UnicodeAnalyzer.char_info(char)
                analysis['char_details'].append(char_info)
            except Exception:
                continue
        
        return analysis

# ä½¿ç”¨ç¤ºä¾‹
analyzer = UnicodeAnalyzer()

# è·å–å­—ç¬¦è¯¦ç»†ä¿¡æ¯
char_info = analyzer.char_info('ä¸­')
print("å­—ç¬¦ 'ä¸­' çš„è¯¦ç»†ä¿¡æ¯:")
for key, value in char_info.items():
    print(f"  {key}: {value}")

# æ¯”è¾ƒå¤šä¸ªå­—ç¬¦
test_chars = ['A', 'a', '1', 'ä¸­', 'Î±', 'ğŸ', 'Â©']
print("\nå­—ç¬¦æ¯”è¾ƒ:")
analyzer.compare_characters(test_chars)

# æŸ¥æ‰¾èŒƒå›´å†…çš„å­—ç¬¦
print("\nå¸Œè…Šå­—æ¯èŒƒå›´ (945-970):")
greek_chars = analyzer.find_chars_in_range(945, 970, 10)
for char_data in greek_chars:
    print(f"  {char_data['char']} ({char_data['code']}) - {char_data['name']}")

# åˆ†æå­—ç¬¦ä¸²
test_string = "Hello ä¸–ç•Œ! ğŸŒ"
string_analysis = analyzer.analyze_string(test_string)
print(f"\nå­—ç¬¦ä¸² '{test_string}' åˆ†æ:")
print(f"  æ€»å­—ç¬¦æ•°: {string_analysis['total_chars']}")
print(f"  å”¯ä¸€å­—ç¬¦æ•°: {string_analysis['unique_chars']}")
print(f"  ç ç‚¹èŒƒå›´: {string_analysis['code_point_range']}")
print(f"  ç¼–ç å¤§å°: UTF-8({string_analysis['encoding_sizes']['utf8']}å­—èŠ‚) "
      f"UTF-16({string_analysis['encoding_sizes']['utf16']}å­—èŠ‚)")
```

### å®é™…åº”ç”¨åœºæ™¯

#### æ–‡æœ¬å¤„ç†å’ŒéªŒè¯

```python
class TextValidator:
    """æ–‡æœ¬éªŒè¯å™¨"""
    
    @staticmethod
    def validate_ascii_only(text):
        """éªŒè¯æ–‡æœ¬æ˜¯å¦åªåŒ…å« ASCII å­—ç¬¦"""
        non_ascii_chars = []
        
        for i, char in enumerate(text):
            if ord(char) > 127:
                non_ascii_chars.append({
                    'char': char,
                    'position': i,
                    'code_point': ord(char),
                    'hex_code': hex(ord(char))
                })
        
        return {
            'is_ascii_only': len(non_ascii_chars) == 0,
            'non_ascii_chars': non_ascii_chars,
            'total_chars': len(text),
            'ascii_chars': len(text) - len(non_ascii_chars)
        }
    
    @staticmethod
    def validate_printable_only(text):
        """éªŒè¯æ–‡æœ¬æ˜¯å¦åªåŒ…å«å¯æ‰“å°å­—ç¬¦"""
        non_printable_chars = []
        
        for i, char in enumerate(text):
            if not char.isprintable() and char not in '\t\n\r':
                non_printable_chars.append({
                    'char': repr(char),
                    'position': i,
                    'code_point': ord(char),
                    'hex_code': hex(ord(char))
                })
        
        return {
            'is_printable_only': len(non_printable_chars) == 0,
            'non_printable_chars': non_printable_chars,
            'total_chars': len(text)
        }
    
    @staticmethod
    def check_character_ranges(text):
        """æ£€æŸ¥å­—ç¬¦æ‰€å±çš„èŒƒå›´"""
        ranges = {
            'ASCIIæ§åˆ¶å­—ç¬¦': (0, 31),
            'ASCIIå¯æ‰“å°': (32, 126),
            'Latin-1è¡¥å……': (128, 255),
            'CJKç»Ÿä¸€æ±‰å­—': (0x4E00, 0x9FFF),
            'emoji': (0x1F600, 0x1F64F),
            'æ•°å­¦ç¬¦å·': (0x2200, 0x22FF),
            'å¸Œè…Šå­—æ¯': (0x0370, 0x03FF)
        }
        
        char_distribution = {name: [] for name in ranges.keys()}
        char_distribution['å…¶ä»–'] = []
        
        for char in text:
            code_point = ord(char)
            categorized = False
            
            for range_name, (start, end) in ranges.items():
                if start <= code_point <= end:
                    char_distribution[range_name].append({
                        'char': char,
                        'code_point': code_point
                    })
                    categorized = True
                    break
            
            if not categorized:
                char_distribution['å…¶ä»–'].append({
                    'char': char,
                    'code_point': code_point
                })
        
        # ç§»é™¤ç©ºçš„åˆ†ç±»
        return {k: v for k, v in char_distribution.items() if v}
    
    @staticmethod
    def suggest_encoding(text):
        """å»ºè®®åˆé€‚çš„ç¼–ç æ–¹å¼"""
        max_code_point = max(ord(char) for char in text) if text else 0
        
        suggestions = []
        
        if max_code_point <= 127:
            suggestions.append({
                'encoding': 'ASCII',
                'reason': 'æ‰€æœ‰å­—ç¬¦éƒ½åœ¨ASCIIèŒƒå›´å†…',
                'efficiency': 'æœ€é«˜'
            })
        
        if max_code_point <= 255:
            suggestions.append({
                'encoding': 'Latin-1 (ISO-8859-1)',
                'reason': 'æ‰€æœ‰å­—ç¬¦éƒ½åœ¨Latin-1èŒƒå›´å†…',
                'efficiency': 'é«˜'
            })
        
        suggestions.append({
            'encoding': 'UTF-8',
            'reason': 'é€šç”¨Unicodeç¼–ç ï¼Œå…¼å®¹æ€§æœ€å¥½',
            'efficiency': 'ä¸­ç­‰åˆ°é«˜ï¼ˆå–å†³äºå­—ç¬¦ç±»å‹ï¼‰'
        })
        
        if max_code_point > 0xFFFF:
            suggestions.append({
                'encoding': 'UTF-32',
                'reason': 'åŒ…å«éœ€è¦4å­—èŠ‚è¡¨ç¤ºçš„å­—ç¬¦',
                'efficiency': 'ä½ï¼ˆå›ºå®š4å­—èŠ‚æ¯å­—ç¬¦ï¼‰'
            })
        
        return {
            'max_code_point': max_code_point,
            'max_code_hex': hex(max_code_point),
            'suggestions': suggestions
        }

# ä½¿ç”¨ç¤ºä¾‹
validator = TextValidator()

# ASCII éªŒè¯
test_text1 = "Hello World!"
test_text2 = "Hello ä¸–ç•Œ!"

ascii_result1 = validator.validate_ascii_only(test_text1)
print(f"'{test_text1}' ASCIIéªŒè¯: {ascii_result1['is_ascii_only']}")

ascii_result2 = validator.validate_ascii_only(test_text2)
print(f"'{test_text2}' ASCIIéªŒè¯: {ascii_result2['is_ascii_only']}")
if not ascii_result2['is_ascii_only']:
    print("  éASCIIå­—ç¬¦:")
    for char_info in ascii_result2['non_ascii_chars']:
        print(f"    ä½ç½®{char_info['position']}: '{char_info['char']}' (ç ç‚¹: {char_info['code_point']})")

# å¯æ‰“å°å­—ç¬¦éªŒè¯
test_text3 = "Hello\x00World\x1F"
printable_result = validator.validate_printable_only(test_text3)
print(f"\nåŒ…å«æ§åˆ¶å­—ç¬¦çš„æ–‡æœ¬å¯æ‰“å°éªŒè¯: {printable_result['is_printable_only']}")
if not printable_result['is_printable_only']:
    print("  éå¯æ‰“å°å­—ç¬¦:")
    for char_info in printable_result['non_printable_chars']:
        print(f"    ä½ç½®{char_info['position']}: {char_info['char']} (ç ç‚¹: {char_info['code_point']})")

# å­—ç¬¦èŒƒå›´æ£€æŸ¥
test_text4 = "Hello ä¸–ç•Œ! Î±Î²Î³ ğŸ âˆ‘âˆâˆ†"
range_result = validator.check_character_ranges(test_text4)
print(f"\n'{test_text4}' å­—ç¬¦èŒƒå›´åˆ†å¸ƒ:")
for range_name, chars in range_result.items():
    char_list = [f"'{c['char']}'({c['code_point']})" for c in chars[:3]]
    if len(chars) > 3:
        char_list.append(f"...è¿˜æœ‰{len(chars)-3}ä¸ª")
    print(f"  {range_name}: {', '.join(char_list)}")

# ç¼–ç å»ºè®®
encoding_suggestion = validator.suggest_encoding(test_text4)
print(f"\nç¼–ç å»ºè®® (æœ€å¤§ç ç‚¹: {encoding_suggestion['max_code_hex']}):")
for suggestion in encoding_suggestion['suggestions']:
    print(f"  {suggestion['encoding']}: {suggestion['reason']} (æ•ˆç‡: {suggestion['efficiency']})")
```

#### å¯†ç å­¦å’Œå“ˆå¸Œåº”ç”¨

```python
import hashlib

class CharacterCrypto:
    """åŸºäºå­—ç¬¦ç ç‚¹çš„å¯†ç å­¦åº”ç”¨"""
    
    @staticmethod
    def simple_caesar_cipher(text, shift):
        """ç®€å•çš„å‡¯æ’’å¯†ç ï¼ˆæ”¯æŒUnicodeï¼‰"""
        encrypted = []
        
        for char in text:
            # è·å–åŸå§‹ç ç‚¹
            original_code = ord(char)
            
            # åº”ç”¨åç§»
            new_code = original_code + shift
            
            # ç¡®ä¿åœ¨æœ‰æ•ˆçš„UnicodeèŒƒå›´å†…
            if new_code > 0x10FFFF:  # Unicodeæœ€å¤§ç ç‚¹
                new_code = new_code % 0x10FFFF
            elif new_code < 0:
                new_code = 0x10FFFF + new_code
            
            try:
                encrypted_char = chr(new_code)
                encrypted.append(encrypted_char)
            except ValueError:
                # å¦‚æœç ç‚¹æ— æ•ˆï¼Œä¿æŒåŸå­—ç¬¦
                encrypted.append(char)
        
        return ''.join(encrypted)
    
    @staticmethod
    def character_checksum(text):
        """åŸºäºå­—ç¬¦ç ç‚¹çš„æ ¡éªŒå’Œ"""
        checksum = 0
        for i, char in enumerate(text):
            # ä½¿ç”¨ä½ç½®æƒé‡è®¡ç®—æ ¡éªŒå’Œ
            checksum += ord(char) * (i + 1)
        
        return checksum % 0xFFFF  # 16ä½æ ¡éªŒå’Œ
    
    @staticmethod
    def text_fingerprint(text):
        """ç”Ÿæˆæ–‡æœ¬æŒ‡çº¹"""
        # æ”¶é›†æ‰€æœ‰å­—ç¬¦çš„ç ç‚¹
        code_points = [ord(char) for char in text]
        
        fingerprint = {
            'length': len(text),
            'unique_chars': len(set(text)),
            'code_point_sum': sum(code_points),
            'code_point_avg': sum(code_points) / len(code_points) if code_points else 0,
            'min_code_point': min(code_points) if code_points else 0,
            'max_code_point': max(code_points) if code_points else 0,
            'checksum': CharacterCrypto.character_checksum(text),
            'md5_hash': hashlib.md5(text.encode('utf-8')).hexdigest()[:16]
        }
        
        return fingerprint
    
    @staticmethod
    def generate_char_based_key(seed_text, key_length=16):
        """åŸºäºå­—ç¬¦ç ç‚¹ç”Ÿæˆå¯†é’¥"""
        if not seed_text:
            raise ValueError("ç§å­æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        # ä½¿ç”¨å­—ç¬¦ç ç‚¹ä½œä¸ºéšæœºç§å­
        seed_value = sum(ord(char) * (i + 1) for i, char in enumerate(seed_text))
        
        # ç”Ÿæˆå¯†é’¥å­—ç¬¦
        key_chars = []
        current_seed = seed_value
        
        for i in range(key_length):
            # ç®€å•çš„çº¿æ€§åŒä½™ç”Ÿæˆå™¨
            current_seed = (current_seed * 1103515245 + 12345) % (2**31)
            
            # å°†ç§å­å€¼æ˜ å°„åˆ°å¯æ‰“å°ASCIIå­—ç¬¦èŒƒå›´ (33-126)
            char_code = 33 + (current_seed % 94)
            key_chars.append(chr(char_code))
        
        return ''.join(key_chars)
    
    @staticmethod
    def analyze_text_entropy(text):
        """åˆ†ææ–‡æœ¬çš„ç†µå€¼"""
        if not text:
            return {'entropy': 0, 'analysis': 'ç©ºæ–‡æœ¬'}
        
        # è®¡ç®—å­—ç¬¦é¢‘ç‡
        char_freq = {}
        for char in text:
            code_point = ord(char)
            if code_point not in char_freq:
                char_freq[code_point] = 0
            char_freq[code_point] += 1
        
        # è®¡ç®—ç†µå€¼
        text_length = len(text)
        entropy = 0
        
        for count in char_freq.values():
            probability = count / text_length
            if probability > 0:
                entropy -= probability * (probability.bit_length() - 1)
        
        analysis = {
            'entropy': entropy,
            'max_possible_entropy': len(char_freq).bit_length() - 1,
            'entropy_ratio': entropy / (len(char_freq).bit_length() - 1) if len(char_freq) > 1 else 0,
            'unique_chars': len(char_freq),
            'total_chars': text_length,
            'most_frequent_char': max(char_freq.items(), key=lambda x: x[1]) if char_freq else None
        }
        
        return analysis

# ä½¿ç”¨ç¤ºä¾‹
crypto = CharacterCrypto()

# å‡¯æ’’å¯†ç 
original_text = "Hello ä¸–ç•Œ!"
shift = 3
encrypted = crypto.simple_caesar_cipher(original_text, shift)
decrypted = crypto.simple_caesar_cipher(encrypted, -shift)

print(f"åŸæ–‡: {original_text}")
print(f"åŠ å¯† (åç§»{shift}): {encrypted}")
print(f"è§£å¯†: {decrypted}")

# å­—ç¬¦æ ¡éªŒå’Œ
checksum = crypto.character_checksum(original_text)
print(f"\n'{original_text}' çš„æ ¡éªŒå’Œ: {checksum} (0x{checksum:04x})")

# æ–‡æœ¬æŒ‡çº¹
fingerprint = crypto.text_fingerprint(original_text)
print(f"\næ–‡æœ¬æŒ‡çº¹:")
for key, value in fingerprint.items():
    print(f"  {key}: {value}")

# ç”Ÿæˆå¯†é’¥
key = crypto.generate_char_based_key(original_text, 16)
print(f"\nåŸºäº '{original_text}' ç”Ÿæˆçš„å¯†é’¥: {key}")

# ç†µå€¼åˆ†æ
entropy_analysis = crypto.analyze_text_entropy(original_text)
print(f"\nç†µå€¼åˆ†æ:")
for key, value in entropy_analysis.items():
    if key == 'most_frequent_char' and value:
        char_code, freq = value
        print(f"  {key}: '{chr(char_code)}'({char_code}) å‡ºç°{freq}æ¬¡")
    else:
        print(f"  {key}: {value}")
```

#### æ•°æ®è½¬æ¢å’Œç¼–ç 

```python
class CharacterEncoder:
    """å­—ç¬¦ç¼–ç è½¬æ¢å™¨"""
    
    @staticmethod
    def to_numeric_codes(text, base=10):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—ç ç‚¹åºåˆ—"""
        codes = [ord(char) for char in text]
        
        if base == 10:
            return codes
        elif base == 16:
            return [hex(code) for code in codes]
        elif base == 8:
            return [oct(code) for code in codes]
        elif base == 2:
            return [bin(code) for code in codes]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¿›åˆ¶: {base}")
    
    @staticmethod
    def from_numeric_codes(codes, base=10):
        """ä»æ•°å­—ç ç‚¹åºåˆ—æ¢å¤æ–‡æœ¬"""
        chars = []
        
        for code in codes:
            try:
                if base == 10:
                    char_code = int(code)
                elif base == 16:
                    char_code = int(str(code).replace('0x', ''), 16)
                elif base == 8:
                    char_code = int(str(code).replace('0o', ''), 8)
                elif base == 2:
                    char_code = int(str(code).replace('0b', ''), 2)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è¿›åˆ¶: {base}")
                
                chars.append(chr(char_code))
            except (ValueError, OverflowError):
                chars.append('?')  # æ— æ•ˆç ç‚¹ç”¨?æ›¿ä»£
        
        return ''.join(chars)
    
    @staticmethod
    def encode_as_escape_sequence(text):
        """ç¼–ç ä¸ºè½¬ä¹‰åºåˆ—"""
        encoded = []
        
        for char in text:
            code_point = ord(char)
            
            if code_point < 32 or code_point > 126:
                # éå¯æ‰“å°å­—ç¬¦ä½¿ç”¨Unicodeè½¬ä¹‰
                if code_point <= 0xFF:
                    encoded.append(f'\\x{code_point:02x}')
                elif code_point <= 0xFFFF:
                    encoded.append(f'\\u{code_point:04x}')
                else:
                    encoded.append(f'\\U{code_point:08x}')
            else:
                # å¯æ‰“å°ASCIIå­—ç¬¦ç›´æ¥ä½¿ç”¨
                if char in '\\"\'':
                    encoded.append('\\' + char)
                else:
                    encoded.append(char)
        
        return ''.join(encoded)
    
    @staticmethod
    def create_character_map(text):
        """åˆ›å»ºå­—ç¬¦æ˜ å°„è¡¨"""
        char_map = {}
        reverse_map = {}
        
        unique_chars = list(set(text))
        unique_chars.sort(key=ord)  # æŒ‰ç ç‚¹æ’åº
        
        for i, char in enumerate(unique_chars):
            char_map[char] = i
            reverse_map[i] = char
        
        return {
            'char_to_index': char_map,
            'index_to_char': reverse_map,
            'mapping_table': [(char, ord(char), i) for i, char in enumerate(unique_chars)]
        }
    
    @staticmethod
    def compress_repeated_chars(text):
        """å‹ç¼©é‡å¤å­—ç¬¦ï¼ˆç®€å•çš„è¡Œç¨‹ç¼–ç ï¼‰"""
        if not text:
            return []
        
        compressed = []
        current_char = text[0]
        count = 1
        
        for char in text[1:]:
            if char == current_char:
                count += 1
            else:
                compressed.append({
                    'char': current_char,
                    'code_point': ord(current_char),
                    'count': count
                })
                current_char = char
                count = 1
        
        # æ·»åŠ æœ€åä¸€ä¸ªå­—ç¬¦ç»„
        compressed.append({
            'char': current_char,
            'code_point': ord(current_char),
            'count': count
        })
        
        return compressed
    
    @staticmethod
    def decompress_repeated_chars(compressed_data):
        """è§£å‹ç¼©é‡å¤å­—ç¬¦"""
        decompressed = []
        
        for item in compressed_data:
            char = item['char']
            count = item['count']
            decompressed.extend([char] * count)
        
        return ''.join(decompressed)

# ä½¿ç”¨ç¤ºä¾‹
encoder = CharacterEncoder()

# æ•°å­—ç ç‚¹è½¬æ¢
test_text = "Hello ä¸–ç•Œ!"
print(f"åŸæ–‡: {test_text}")

# è½¬æ¢ä¸ºä¸åŒè¿›åˆ¶çš„ç ç‚¹
decimal_codes = encoder.to_numeric_codes(test_text, 10)
hex_codes = encoder.to_numeric_codes(test_text, 16)
print(f"åè¿›åˆ¶ç ç‚¹: {decimal_codes}")
print(f"åå…­è¿›åˆ¶ç ç‚¹: {hex_codes}")

# ä»ç ç‚¹æ¢å¤æ–‡æœ¬
restored_text = encoder.from_numeric_codes(decimal_codes, 10)
print(f"æ¢å¤çš„æ–‡æœ¬: {restored_text}")

# è½¬ä¹‰åºåˆ—ç¼–ç 
escaped = encoder.encode_as_escape_sequence(test_text)
print(f"\nè½¬ä¹‰åºåˆ—: {escaped}")

# å­—ç¬¦æ˜ å°„è¡¨
char_mapping = encoder.create_character_map(test_text)
print(f"\nå­—ç¬¦æ˜ å°„è¡¨:")
for char, code_point, index in char_mapping['mapping_table']:
    print(f"  '{char}' (ç ç‚¹{code_point}) -> ç´¢å¼•{index}")

# é‡å¤å­—ç¬¦å‹ç¼©
repeat_text = "aaabbbcccdddeee"
compressed = encoder.compress_repeated_chars(repeat_text)
decompressed = encoder.decompress_repeated_chars(compressed)

print(f"\nåŸæ–‡: {repeat_text}")
print(f"å‹ç¼©ç»“æœ:")
for item in compressed:
    print(f"  '{item['char']}' x {item['count']}")
print(f"è§£å‹ç»“æœ: {decompressed}")
print(f"å‹ç¼©ç‡: {len(compressed)}/{len(repeat_text)} = {len(compressed)/len(repeat_text):.2%}")
```

### å¸¸è§é™·é˜±å’Œæœ€ä½³å®è·µ

#### é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ

```python
class SafeOrdProcessor:
    """å®‰å…¨çš„ ord() å¤„ç†å™¨"""
    
    @staticmethod
    def safe_ord(value):
        """å®‰å…¨çš„ ord() è°ƒç”¨"""
        try:
            # æ£€æŸ¥è¾“å…¥ç±»å‹
            if not isinstance(value, str):
                return {
                    'success': False,
                    'error': f"è¾“å…¥å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œå®é™…ç±»å‹: {type(value).__name__}",
                    'code_point': None
                }
            
            # æ£€æŸ¥é•¿åº¦
            if len(value) != 1:
                return {
                    'success': False,
                    'error': f"è¾“å…¥å¿…é¡»æ˜¯å•ä¸ªå­—ç¬¦ï¼Œå®é™…é•¿åº¦: {len(value)}",
                    'code_point': None
                }
            
            # æ‰§è¡Œè½¬æ¢
            code_point = ord(value)
            
            return {
                'success': True,
                'error': None,
                'code_point': code_point,
                'hex_code': hex(code_point),
                'character': value
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"æœªçŸ¥é”™è¯¯: {str(e)}",
                'code_point': None
            }
    
    @staticmethod
    def batch_ord_safe(text):
        """æ‰¹é‡å®‰å…¨å¤„ç†å­—ç¬¦ä¸²ä¸­çš„æ¯ä¸ªå­—ç¬¦"""
        results = {
            'successful': [],
            'failed': [],
            'summary': {
                'total_chars': len(text),
                'success_count': 0,
                'error_count': 0
            }
        }
        
        for i, char in enumerate(text):
            result = SafeOrdProcessor.safe_ord(char)
            
            if result['success']:
                results['successful'].append({
                    'position': i,
                    'character': char,
                    'code_point': result['code_point'],
                    'hex_code': result['hex_code']
                })
                results['summary']['success_count'] += 1
            else:
                results['failed'].append({
                    'position': i,
                    'character': char,
                    'error': result['error']
                })
                results['summary']['error_count'] += 1
        
        return results
    
    @staticmethod
    def validate_unicode_range(char, min_code=0, max_code=0x10FFFF):
        """éªŒè¯å­—ç¬¦æ˜¯å¦åœ¨æŒ‡å®šçš„UnicodeèŒƒå›´å†…"""
        try:
            code_point = ord(char)
            
            if min_code <= code_point <= max_code:
                return {
                    'valid': True,
                    'code_point': code_point,
                    'message': f"å­—ç¬¦ '{char}' åœ¨èŒƒå›´ [{min_code}, {max_code}] å†…"
                }
            else:
                return {
                    'valid': False,
                    'code_point': code_point,
                    'message': f"å­—ç¬¦ '{char}' (ç ç‚¹{code_point}) è¶…å‡ºèŒƒå›´ [{min_code}, {max_code}]"
                }
                
        except Exception as e:
            return {
                'valid': False,
                'code_point': None,
                'message': f"å¤„ç†å­—ç¬¦ '{char}' æ—¶å‡ºé”™: {str(e)}"
            }
    
    @staticmethod
    def find_problematic_chars(text, encoding='utf-8'):
        """æŸ¥æ‰¾åœ¨æŒ‡å®šç¼–ç ä¸‹å¯èƒ½æœ‰é—®é¢˜çš„å­—ç¬¦"""
        problematic = []
        
        for i, char in enumerate(text):
            try:
                # å°è¯•ç¼–ç 
                char.encode(encoding)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºä»£ç†å¯¹ï¼ˆåœ¨UTF-16ä¸­ä½¿ç”¨ï¼‰
                code_point = ord(char)
                if 0xD800 <= code_point <= 0xDFFF:
                    problematic.append({
                        'position': i,
                        'character': char,
                        'code_point': code_point,
                        'issue': 'ä»£ç†å¯¹å­—ç¬¦ï¼Œåœ¨æŸäº›ä¸Šä¸‹æ–‡ä¸­å¯èƒ½æœ‰é—®é¢˜'
                    })
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç§ç”¨åŒºå­—ç¬¦
                elif (0xE000 <= code_point <= 0xF8FF or
                      0xF0000 <= code_point <= 0xFFFFD or
                      0x100000 <= code_point <= 0x10FFFD):
                    problematic.append({
                        'position': i,
                        'character': char,
                        'code_point': code_point,
                        'issue': 'ç§ç”¨åŒºå­—ç¬¦ï¼Œæ˜¾ç¤ºå¯èƒ½å› ç³»ç»Ÿè€Œå¼‚'
                    })
                
            except UnicodeEncodeError as e:
                problematic.append({
                    'position': i,
                    'character': char,
                    'code_point': ord(char),
                    'issue': f'æ— æ³•ç”¨{encoding}ç¼–ç : {str(e)}'
                })
        
        return problematic

# ä½¿ç”¨ç¤ºä¾‹
safe_processor = SafeOrdProcessor()

# å®‰å…¨çš„ ord() è°ƒç”¨
test_cases = ['A', 'Hello', '', 123, None, 'ä¸­']
print("å®‰å…¨ ord() æµ‹è¯•:")
for test_case in test_cases:
    result = safe_processor.safe_ord(test_case)
    if result['success']:
        print(f"  '{test_case}' -> {result['code_point']} ({result['hex_code']})")
    else:
        print(f"  {test_case} -> é”™è¯¯: {result['error']}")

# æ‰¹é‡å¤„ç†
test_string = "Hello ä¸–ç•Œ! ğŸŒ"
batch_result = safe_processor.batch_ord_safe(test_string)
print(f"\næ‰¹é‡å¤„ç† '{test_string}':")
print(f"  æˆåŠŸ: {batch_result['summary']['success_count']} ä¸ªå­—ç¬¦")
print(f"  å¤±è´¥: {batch_result['summary']['error_count']} ä¸ªå­—ç¬¦")

# æ˜¾ç¤ºå‰å‡ ä¸ªæˆåŠŸçš„ç»“æœ
for item in batch_result['successful'][:5]:
    print(f"    ä½ç½®{item['position']}: '{item['character']}' -> {item['code_point']}")

# UnicodeèŒƒå›´éªŒè¯
print("\nUnicodeèŒƒå›´éªŒè¯:")
test_chars = ['A', 'ä¸­', 'ğŸŒ', '\uD800']  # æœ€åä¸€ä¸ªæ˜¯ä»£ç†å¯¹
for char in test_chars:
    # éªŒè¯æ˜¯å¦åœ¨åŸºæœ¬å¤šè¯­è¨€å¹³é¢ (BMP) å†…
    result = safe_processor.validate_unicode_range(char, 0, 0xFFFF)
    print(f"  {result['message']}")

# æŸ¥æ‰¾é—®é¢˜å­—ç¬¦
problematic_text = "Hello\uD800\uDC00World"  # åŒ…å«ä»£ç†å¯¹
problems = safe_processor.find_problematic_chars(problematic_text)
print(f"\nåœ¨ '{repr(problematic_text)}' ä¸­å‘ç°çš„é—®é¢˜:")
for problem in problems:
    print(f"  ä½ç½®{problem['position']}: {problem['issue']}")
```

#### æ€§èƒ½ä¼˜åŒ–

```python
import time
from functools import lru_cache

class OrdPerformance:
    """ord() æ€§èƒ½ä¼˜åŒ–"""
    
    @staticmethod
    @lru_cache(maxsize=1000)
    def cached_ord(char):
        """ç¼“å­˜çš„ ord() è°ƒç”¨"""
        return ord(char)
    
    @staticmethod
    def batch_ord_optimized(text):
        """ä¼˜åŒ–çš„æ‰¹é‡ ord() å¤„ç†"""
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ï¼Œæ¯”å¾ªç¯æ›´å¿«
        return [ord(char) for char in text]
    
    @staticmethod
    def ord_with_lookup_table(text, use_cache=True):
        """ä½¿ç”¨æŸ¥æ‰¾è¡¨çš„ ord() å¤„ç†"""
        if use_cache:
            return [OrdPerformance.cached_ord(char) for char in text]
        else:
            return [ord(char) for char in text]
    
    @staticmethod
    def performance_comparison(test_text, iterations=1000):
        """æ€§èƒ½æ¯”è¾ƒæµ‹è¯•"""
        methods = {
            'æ™®é€šord()': lambda text: [ord(char) for char in text],
            'ç¼“å­˜ord()': lambda text: [OrdPerformance.cached_ord(char) for char in text],
            'æ‰¹é‡ä¼˜åŒ–': OrdPerformance.batch_ord_optimized
        }
        
        results = {}
        
        for method_name, method_func in methods.items():
            start_time = time.time()
            
            for _ in range(iterations):
                result = method_func(test_text)
            
            end_time = time.time()
            results[method_name] = {
                'time': end_time - start_time,
                'avg_time': (end_time - start_time) / iterations
            }
        
        return results
    
    @staticmethod
    def memory_efficient_ord_processing(large_text):
        """å†…å­˜é«˜æ•ˆçš„å¤§æ–‡æœ¬å¤„ç†"""
        def ord_generator(text):
            """ord() ç”Ÿæˆå™¨ï¼ŒèŠ‚çœå†…å­˜"""
            for char in text:
                yield ord(char)
        
        # åˆ†å—å¤„ç†å¤§æ–‡æœ¬
        chunk_size = 10000
        processed_count = 0
        code_point_stats = {
            'min': float('inf'),
            'max': 0,
            'sum': 0,
            'count': 0
        }
        
        for i in range(0, len(large_text), chunk_size):
            chunk = large_text[i:i + chunk_size]
            ord_gen = ord_generator(chunk)
            
            for code_point in ord_gen:
                processed_count += 1
                code_point_stats['min'] = min(code_point_stats['min'], code_point)
                code_point_stats['max'] = max(code_point_stats['max'], code_point)
                code_point_stats['sum'] += code_point
                code_point_stats['count'] += 1
            
            if processed_count % 100000 == 0:
                print(f"å·²å¤„ç† {processed_count} ä¸ªå­—ç¬¦")
        
        code_point_stats['avg'] = code_point_stats['sum'] / code_point_stats['count']
        return code_point_stats

# æ€§èƒ½æµ‹è¯•
perf = OrdPerformance()

# ç”Ÿæˆæµ‹è¯•æ–‡æœ¬
test_text = "Hello World! ä½ å¥½ä¸–ç•Œ! Î±Î²Î³Î´Îµ ğŸŒğŸš€ğŸ‰" * 100

print(f"æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
print("æ€§èƒ½æ¯”è¾ƒæµ‹è¯• (1000æ¬¡è¿­ä»£):")

# æ€§èƒ½æ¯”è¾ƒ
perf_results = perf.performance_comparison(test_text, 1000)

sorted_results = sorted(perf_results.items(), key=lambda x: x[1]['time'])
for method, stats in sorted_results:
    print(f"  {method:<12}: {stats['time']:.6f}ç§’ (å¹³å‡: {stats['avg_time']:.8f}ç§’)")

# è®¡ç®—æ€§èƒ½æå‡
fastest_time = sorted_results[0][1]['time']
print("\næ€§èƒ½æå‡æ¯”è¾ƒ:")
for method, stats in sorted_results:
    speedup = fastest_time / stats['time']
    print(f"  {method:<12}: {speedup:.2f}x")

# å¤§æ–‡æœ¬å†…å­˜æ•ˆç‡æµ‹è¯•
print("\nå¤§æ–‡æœ¬å†…å­˜æ•ˆç‡æµ‹è¯•:")
large_text = test_text * 1000  # çº¦100ä¸‡å­—ç¬¦
stats = perf.memory_efficient_ord_processing(large_text)
print(f"å¤„ç†å®Œæˆï¼Œç»Ÿè®¡ç»“æœ:")
print(f"  å­—ç¬¦æ•°: {stats['count']}")
print(f"  æœ€å°ç ç‚¹: {stats['min']} ('{chr(stats['min'])}')") 
print(f"  æœ€å¤§ç ç‚¹: {stats['max']} ('{chr(stats['max']) if stats['max'] <= 0x10FFFF else 'æ— æ•ˆ'}')")
print(f"  å¹³å‡ç ç‚¹: {stats['avg']:.2f}")
```

## ç›¸å…³å‡½æ•°å’Œæ¨¡å—

### å†…ç½®å‡½æ•°
- `chr()` - Unicodeç ç‚¹è½¬å­—ç¬¦ï¼ˆordçš„é€†æ“ä½œï¼‰
- `hex()` - æ•´æ•°è½¬åå…­è¿›åˆ¶å­—ç¬¦ä¸²
- `bin()` - æ•´æ•°è½¬äºŒè¿›åˆ¶å­—ç¬¦ä¸²
- `int()` - å­—ç¬¦ä¸²è½¬æ•´æ•°

### æ ‡å‡†åº“
- `unicodedata` - Unicodeå­—ç¬¦æ•°æ®åº“
- `codecs` - ç¼–è§£ç å™¨æ³¨å†Œå’ŒåŸºç±»
- `string` - å­—ç¬¦ä¸²å¸¸é‡å’Œç±»
- `re` - æ­£åˆ™è¡¨è¾¾å¼æ“ä½œ

### ç¬¬ä¸‰æ–¹åº“
- `unidecode` - Unicodeæ–‡æœ¬è½¬ASCII
- `chardet` - å­—ç¬¦ç¼–ç æ£€æµ‹
- `ftfy` - ä¿®å¤Unicodeæ–‡æœ¬

## æ‰©å±•é˜…è¯»

- [Python å®˜æ–¹æ–‡æ¡£ - ord()](https://docs.python.org/3/library/functions.html#ord)
- [Unicode æ ‡å‡†](https://unicode.org/standard/standard.html)
- [UTF-8 ç¼–ç è¯¦è§£](https://en.wikipedia.org/wiki/UTF-8)
- [Python Unicode HOWTO](https://docs.python.org/3/howto/unicode.html)

## æ ‡ç­¾

`å†…ç½®å‡½æ•°` `Unicode` `å­—ç¬¦ç¼–ç ` `æ–‡æœ¬å¤„ç†` `ç ç‚¹è½¬æ¢` `å­—ç¬¦ä¸²æ“ä½œ` `å›½é™…åŒ–` `ç¼–ç è½¬æ¢`